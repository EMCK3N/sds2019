{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Set 4: Data Structuring 1\n",
    "\n",
    "*Afternoon, August 13, 2019*\n",
    "\n",
    "In this Exercise Set we will apply some of the basic things we have learned with pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load modules\n",
    "We begin by loading relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exercise Section 4.1: Weather, part 1\n",
    "\n",
    "Some data sources are open and easy to collect data from. They can be 'scraped' as is and they are already in a table format. This Exercise part of exercises is the first part of three that work with weather data, the follow ups are Exercise Sections 6.1 and 7.1. Our source will be National Oceanic and Atmospheric Administration (NOAA) which have a global data collection going back a couple of centuries. This collection is called Global Historical Climatology Network (GHCN). A description of GHCN can be found [here](https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/readme.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **Ex. 4.1.1:** Use Pandas' CSV reader to fetch  daily data weather from 1864 for various stations - available [here](https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/). \n",
    "\n",
    "> *Hint 1*: for compressed files you may need to specify the keyword `compression`.\n",
    "\n",
    "> *Hint 2*: keyword `header` can be specified as the CSV has no column names.\n",
    "\n",
    "> *Hint 3*: Specify the path, as the URL linking directly to the 1864 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ITE00100550  18640101  TMAX   10 Unnamed: 4 Unnamed: 5  E  Unnamed: 7\n",
      "0  ITE00100550  18640101  TMIN  -23        NaN        NaN  E         NaN\n",
      "1  ITE00100550  18640101  PRCP   25        NaN        NaN  E         NaN\n",
      "2  ASN00079028  18640101  PRCP    0        NaN        NaN  a         NaN\n",
      "3  USC00064757  18640101  PRCP  119        NaN        NaN  F         NaN\n",
      "4  SF000208660  18640101  PRCP    0        NaN        NaN  I         NaN\n",
      "5  ASN00089000  18640101  PRCP    0        NaN        NaN  a         NaN\n",
      "6  SWE00100003  18640101  PRCP    0        NaN        NaN  E         NaN\n",
      "7  ASN00086071  18640101  TMAX  214        NaN        NaN  a         NaN\n",
      "8  ASN00086071  18640101  TMIN  101        NaN        NaN  a         NaN\n",
      "9  ASN00086071  18640101  PRCP    0        NaN        NaN  a         NaN\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.1]\n",
    "url = 'https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/1864.csv.gz'\n",
    "path = '1864.csv' #local path to physical file on my computer\n",
    "df = pd.read_csv(url, sep=',') # open the file as dataframe\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **Ex. 4.1.2:** Structure your weather DataFrame by using only the relevant columns (station identifier, data, observation type, observation value), rename them. Make sure observations are correctly formated (how many decimals should we add? one?).\n",
    "\n",
    "> *Hint:* rename can be done with `df.columns=COLS` where `COLS` is a list of column names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  station identifier      date observation type  observation value\n",
      "0        ITE00100550  18640101             TMIN                -23\n",
      "1        ITE00100550  18640101             PRCP                 25\n",
      "2        ASN00079028  18640101             PRCP                  0\n",
      "3        USC00064757  18640101             PRCP                119\n",
      "4        SF000208660  18640101             PRCP                  0\n",
      "5        ASN00089000  18640101             PRCP                  0\n",
      "6        SWE00100003  18640101             PRCP                  0\n",
      "7        ASN00086071  18640101             TMAX                214\n",
      "8        ASN00086071  18640101             TMIN                101\n",
      "9        ASN00086071  18640101             PRCP                  0\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.2]\n",
    "df_columns = ['station identifier', 'date', 'observation type', 'observation value', 'NaN', 'NaN', 'NaN', 'NaN']\n",
    "df.columns = df_columns\n",
    "\n",
    "df\n",
    "weather = df.loc[:,['station identifier', 'date', 'observation type', 'observation value']]\n",
    "#weather = df[0:]\n",
    "print(weather.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **Ex. 4.1.3:**  Select data for the station `ITE00100550` and only observations for maximal temperature. Make a copy of the DataFrame. Explain in a one or two sentences how copying works.\n",
    "\n",
    "> *Hint 1*: the `&` operator works elementwise on boolean series (like `and` in core python).\n",
    "\n",
    "> *Hint 2*: copying of the dataframe is done with the `copy` method for DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    station identifier      date observation type  observation value\n",
      "74         ITE00100550  18640102             TMAX                  8\n",
      "151        ITE00100550  18640103             TMAX                -28\n",
      "226        ITE00100550  18640104             TMAX                  0\n",
      "304        ITE00100550  18640105             TMAX                -19\n",
      "382        ITE00100550  18640106             TMAX                -13\n",
      "459        ITE00100550  18640107             TMAX                 -4\n",
      "537        ITE00100550  18640108             TMAX                 13\n",
      "617        ITE00100550  18640109             TMAX                 13\n",
      "694        ITE00100550  18640110             TMAX                  6\n",
      "769        ITE00100550  18640111             TMAX                -15\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.3]\n",
    "weather = df.loc[:,['station identifier', 'date', 'observation type', 'observation value']]\n",
    "weather_ITE550 = weather.loc[(weather['station identifier'] == 'ITE00100550') & (weather['observation type'] == 'TMAX')].copy()\n",
    "print(weather_ITE550.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.1.4:** Make a new column called `TMAX_F` where you have converted the temperature variables to Fahrenheit. \n",
    "\n",
    "> *Hint*: Conversion is $F = 32 + 1.8*C$ where $F$ is Fahrenheit and $C$ is Celsius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  station identifier      date observation type  observation value  TMAX_F\n",
      "0        ITE00100550  18640101             TMIN                -23    -9.4\n",
      "1        ITE00100550  18640101             PRCP                 25    77.0\n",
      "2        ASN00079028  18640101             PRCP                  0    32.0\n",
      "3        USC00064757  18640101             PRCP                119   246.2\n",
      "4        SF000208660  18640101             PRCP                  0    32.0\n",
      "5        ASN00089000  18640101             PRCP                  0    32.0\n",
      "6        SWE00100003  18640101             PRCP                  0    32.0\n",
      "7        ASN00086071  18640101             TMAX                214   417.2\n",
      "8        ASN00086071  18640101             TMIN                101   213.8\n",
      "9        ASN00086071  18640101             PRCP                  0    32.0\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.4]\n",
    "weather['TMAX_F'] = 32 + 1.8*weather['observation value']\n",
    "print(weather.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex 4.1.5:**  Inspect the indices, are they following the sequence of natural numbers, 0,1,2,...? If not, reset the index and make sure to drop the old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.1.5]\n",
    "#Yes, they are following the sequence of 0 to ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex 4.1.6:** Make a new DataFrame where you have sorted by the maximum temperature. What is the date for the first and last observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     station identifier      date observation type  observation value  TMAX_F\n",
      "9168        ASN00061055  18640430             PRCP               1448  2638.4\n",
      "     station identifier      date observation type  observation value   TMAX_F\n",
      "2668        UK000047811  18640204             PRCP              -6660 -11956.0\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 4.1.6]\n",
    "weather_sort_max = weather.sort_values(by='observation value', ascending=False)\n",
    "print(weather_sort_max.head(1))\n",
    "print(weather_sort_max.tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex 4.1.7:** CSV-files: save your DataFrame as a CSV file. what does index argument do?\n",
    "\n",
    "> Try to save the file using a relative path and an absolut path. \n",
    "With a relative you only specify the file name. This will save the file in the folder you are currently working in. With an absolute path, you specify the whole path, which allows you to save the file in a folder of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 4.1.7]\n",
    "weather.to_csv('my_weather.csv', index=False)\n",
    "# Index argument states if we want to bring in the index to our file. In our case it's 0 to ..... We don't need it, so i have chosen False\n",
    "weather.to_csv('my_weather.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **(Bonus) Ex. 4.1.8**: A very compact way of writing code and making list in Python, is called list comprehensions. Depending on what you are doing, list can be more or less efficient that for example vectorized operations using NumPy. \n",
    "\n",
    ">Read about list comprehenseions online, and use it to make a list with the numbers from 0 to a million (10\\*\\*6), and add 3 to each element. Do the same doing NumPy, and time both methods. Which method is faster? \n",
    "\n",
    "> *Hint 1*: Use the `timeit` package for timing each method "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
