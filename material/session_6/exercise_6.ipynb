{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "# Exercise Set 6: Data Structuring 2\n",
    "\n",
    "*Afternoon, August 14, 2019*\n",
    "\n",
    "In this Exercise Set we will continue working with the weather data you downloaded and saved in Exercise Set 4. \n",
    "\n",
    "> **_Note_**: to solve the bonus exercises in this exerise set you will need to apply the `.groupby()` method a few times. This has not yet been covered in the lectures (you will see it tomorrow).  \n",
    ">\n",
    "> `.groupby()` is a method of pandas dataframes, meaning we can call it like so: `data.groupby('colname')`. The method groups your dataset by a specified column, and applies any following changes within each of these groups. For a more detailed explanation see [this link](https://www.tutorialspoint.com/python_pandas/python_pandas_groupby.htm). The [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html) might also be useful.\n",
    "\n",
    "First load in the required modules and set up the plotting library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Section 6.1: Weather, part 2\n",
    "\n",
    "This section is the second part of three that analyzes NOAA data. The first part is Exercise Section 4.1, the last part is Exercise Section 7.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.1:** Load the CSV data you stored yesterday as part of Exercise Section 4.1. If you didn't manage to save the CSV file, you can use the code in [this gist](https://gist.github.com/Kristianuruplarsen/be3a14b226fc4c4d7b62c39de70307e4) to load in the NOAA data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  station identifier      date observation type  observation value  TMAX_F\n",
      "0        ITE00100550  18640101             TMIN                -23    -9.4\n",
      "1        ITE00100550  18640101             PRCP                 25    77.0\n",
      "2        ASN00079028  18640101             PRCP                  0    32.0\n",
      "3        USC00064757  18640101             PRCP                119   246.2\n",
      "4        SF000208660  18640101             PRCP                  0    32.0\n",
      "5        ASN00089000  18640101             PRCP                  0    32.0\n",
      "6        SWE00100003  18640101             PRCP                  0    32.0\n",
      "7        ASN00086071  18640101             TMAX                214   417.2\n",
      "8        ASN00086071  18640101             TMIN                101   213.8\n",
      "9        ASN00086071  18640101             PRCP                  0    32.0\n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 6.1.1]\n",
    "\n",
    "url = 'https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/1864.csv.gz'\n",
    "path = '/Users/michaelemcken/Google Drive/Python/sds2019/material/session_4/my_weather.csv'\n",
    "df = pd.read_csv(path, sep=',')\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.2:** Convert the date formatted as string to  datetime. Make a new column with the month for each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  station identifier       date observation type  observation value  TMAX_F  \\\n",
      "0        ITE00100550 1864-01-01             TMIN                -23    -9.4   \n",
      "1        ITE00100550 1864-01-01             PRCP                 25    77.0   \n",
      "2        ASN00079028 1864-01-01             PRCP                  0    32.0   \n",
      "3        USC00064757 1864-01-01             PRCP                119   246.2   \n",
      "4        SF000208660 1864-01-01             PRCP                  0    32.0   \n",
      "5        ASN00089000 1864-01-01             PRCP                  0    32.0   \n",
      "6        SWE00100003 1864-01-01             PRCP                  0    32.0   \n",
      "7        ASN00086071 1864-01-01             TMAX                214   417.2   \n",
      "8        ASN00086071 1864-01-01             TMIN                101   213.8   \n",
      "9        ASN00086071 1864-01-01             PRCP                  0    32.0   \n",
      "\n",
      "   month  \n",
      "0      1  \n",
      "1      1  \n",
      "2      1  \n",
      "3      1  \n",
      "4      1  \n",
      "5      1  \n",
      "6      1  \n",
      "7      1  \n",
      "8      1  \n",
      "9      1  \n"
     ]
    }
   ],
   "source": [
    "# [Answer to Ex. 6.1.2]\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')\n",
    "\n",
    "df['month'] = pd.DatetimeIndex(df['date']).month\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.3:** Set the datetime variable as temporal index and make a timeseries plot.\n",
    "\n",
    "> _Hint:_ for this you need to know a few methods of the pandas DataFrames and pandas Series objects. Look up `.set_index()` and `.plot()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 6.1.3]\n",
    "df = df.set_index(['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.plotting._core.FramePlotMethods object at 0x116a9c160>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.4:** Extract the country code from the station name into a separate column.\n",
    "\n",
    "> _Hint:_ The station column contains a GHCND ID, given to each weather station by NOAA. The format of these ID's is a 2-3 letter country code, followed by a integer identifying the specific station. A simple approach is to assume a fixed length of the country ID. A more complex way would be to use the [`re`](https://docs.python.org/2/library/re.html) module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 6.1.4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.5:** Make a function that downloads and formats the weather data according to previous exercises in Exercise Section 4.1, 6.1. You should use data for ALL stations but still only select maximal temperature. _Bonus:_ To validate that your function works plot the temperature curve for each country in the same window. Use `plt.legend()` to add a legend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 6.1.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exercise Section 6.2: \n",
    "\n",
    "In this section we will use [this dataset](https://archive.ics.uci.edu/ml/datasets/Adult) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets.html) to practice some basic operations on pandas dataframes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.2.1:** This link `'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'` leads to a comma-separated file with income data from a US census. Load the data into a pandas dataframe and show the 25th to 35th row.\n",
    "\n",
    "> _Hint #1:_ There are no column names in the dataset. Use the list `['age','workclass', 'fnlwgt', 'educ', 'educ_num', 'marital_status', 'occupation','relationship', 'race', 'sex','capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'wage']` as names. \n",
    "\n",
    "> _Hint #2:_ When you read in the csv, you might find that pandas includes whitespace in all of the cells. To get around this include the argument `skipinitialspace = True` to `read_csv()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 6.2.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.2.2:** What is the missing value sign in this dataset? Replace all missing values with NA's understood by pandas. Then proceed to drop all rows containing any missing values with the  `dropna` method. How many rows are removed in this operation?\n",
    "\n",
    "> _Hint 1:_ if this doesn't work as expected you might want to take a look at the hint for 6.2.1 again.\n",
    " \n",
    "> _Hint 2:_ The NaN method from NumPy might be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 6.2.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.2.3:** (_Bonus_) Is there any evidence of a gender-wage-gap in the data? Create a table showing the percentage of men and women earning more than 50K a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 6.2.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.2.4:** (_Bonus_) Group the data by years of education (`educ_num`) and marital status. Now plot the share of individuals who earn more than 50K for the two groups 'Divorced' and 'Married-civ-spouse' (normal marriage). Your final result should look like this: \n",
    "\n",
    "![](examplefig.png)\n",
    "\n",
    "> _Hint:_ the `.query()` method is extremely useful for filtering data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 6.2.4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
