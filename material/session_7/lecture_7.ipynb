{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data structuring, part III\n",
    "\n",
    "### The Pandas way\n",
    "\n",
    "*Andreas Bjerre-Nielsen*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 10 things I hate about pandas\n",
    "\n",
    "- Correction: Integers and NaN do work now!\n",
    "- Check out this [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/integer_na.html) from July 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap\n",
    "\n",
    "*Which datatypes beyond numeric does pandas handle natively?*\n",
    "\n",
    "- .\n",
    "\n",
    "*What can we do to missing values and duplicates?*\n",
    "\n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "1. [the split apply combine framework](#Split-apply-combine)\n",
    "1. [joining datasets](#Joining-data)\n",
    "1. [reshaping data](#Reshaping-data)\n",
    "1. [methods chaining](#Methods-chaining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading the software and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "tips = sns.load_dataset('tips')\n",
    "titanic = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reshaping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "A DataFrame can be collapsed into a Series with the **stack** command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      EU  US\n",
      "2000   1   2\n",
      "2010   3   4 \n",
      "\n",
      "   level_0 level_1  0\n",
      "0     2000      EU  1\n",
      "1     2000      US  2\n",
      "2     2010      EU  3\n",
      "3     2010      US  4\n",
      "   year place  value\n",
      "0  2000    EU      1\n",
      "1  2000    US      2\n",
      "2  2010    EU      3\n",
      "3  2010    US      4\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[1,2],[3,4]],columns=['EU','US'],index=[2000,2010])\n",
    "print(df, '\\n')\n",
    "stacked = df.stack() # going from wide to long format \n",
    "\n",
    "stacked=stacked.reset_index()\n",
    "print(stacked)\n",
    "stacked.columns = ['year', 'place', 'value']\n",
    "print(stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note: The stacked DataFrame is in long/tidy format, the original is wide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## To wide format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Likewise we can transform a long DataFrame with the unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000  EU    1\n",
      "      US    2\n",
      "2010  EU    3\n",
      "      US    4\n",
      "dtype: int64\n",
      "\n",
      "      EU  US\n",
      "2000   1   2\n",
      "2010   3   4\n"
     ]
    }
   ],
   "source": [
    "print(df.stack())\n",
    "print()\n",
    "print(df.stack().unstack(level=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other cool functions include\n",
    "- `melt` which only stacks certain columns\n",
    "- `pivot` which makes you to reshape the dataframe like in Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Split-apply-combine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Split-apply-combine (1)\n",
    "*What is the split-apply-combine framework?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A procedure to \n",
    "1. **split** a DataFrame into subsets of data\n",
    "2. **apply** certain functions (sorting, mean, other custom stuff)\n",
    "3. **combine** it back into a DataFrame\n",
    "\n",
    "Application example: compute mean personal income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Split-apply-combine (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we *split* observations by x and *apply* the calculation mean of y?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center><img src='https://raw.githubusercontent.com/abjer/sds2017/master/slides/figures/split-apply-combine.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## groupby (1)\n",
    "\n",
    "A powerful tool in DataFrames is the `groupby` method. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "Male      20.744076\n",
       "Female    18.056897\n",
       "Name: total_bill, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_var = 'sex'\n",
    "apply_var = 'total_bill'\n",
    "\n",
    "tips\\\n",
    "    .groupby(split_var)\\\n",
    "    [apply_var]\\\n",
    "     .mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## groupby (2)\n",
    "*What does the `groupby` method do?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It implements *split-apply-combine*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can other functions be applied?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Yes: `mean`, `std`, `min`, `max` all work. \n",
    "- Using `.apply()` method and inserting your ***homemade*** function works too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## groupby (3)\n",
    "*Does `groupby` work for multiple variables, functions?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex    time total_bill                        tip                 \n",
      "                        mean       std median      mean       std median\n",
      "0    Male   Lunch  18.048485  7.953435  16.58  2.882121  1.329017   2.31\n",
      "1    Male  Dinner  21.461452  9.460974  19.63  3.144839  1.529116   3.00\n",
      "2  Female   Lunch  16.339143  7.500803  13.42  2.582857  1.075108   2.01\n",
      "3  Female  Dinner  19.213077  8.202085  17.19  3.002115  1.193483   3.00\n"
     ]
    }
   ],
   "source": [
    "split_vars = ['sex', 'time'] \n",
    "apply_vars = ['total_bill', 'tip']\n",
    "apply_fcts = ['mean', 'std', 'median']\n",
    "combined = tips\\\n",
    "    .groupby(split_vars)\\\n",
    "    [apply_vars]\\\n",
    "    .agg(apply_fcts)\n",
    "\n",
    "print(combined.reset_index() )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Note grouping with multiple variables uses a [MultiIndex](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.MultiIndex.html) which we do not cover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## groupby (4)\n",
    "*Can we use `groupby` in a loop?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Yes, we can iterate over a groupby object. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Male': 20.744076433121034, 'Female': 18.056896551724137}\n"
     ]
    }
   ],
   "source": [
    "results ={}\n",
    "for group, group_df in tips.groupby('sex'):\n",
    "    results[group] = group_df.total_bill.mean()\n",
    "\n",
    "print(results)\n",
    "\n",
    "#results = {}\n",
    "#for group, group_df in tips.groupby('sex'):\n",
    "#    group_mean = group_df.total_bill.mean()\n",
    "#    results[group] = group_mean\n",
    "#    \n",
    "#    \n",
    "#print(group)\n",
    "#results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ProTip: `groupby` is an iterable we can also use with `multiprocessing` for parallel computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## groupby (5)\n",
    "*How do we get our `groupby` output into the original dataframe?*\n",
    "\n",
    "- Option 1: you use `transform`.\n",
    "\n",
    "- Option 2: you merge it (not recommended)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -1.066897\n",
       "1   -10.404076\n",
       "2     0.265924\n",
       "3     2.935924\n",
       "4     6.533103\n",
       "Name: total_bill, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_sex = tips.groupby(split_var)[apply_var].transform('mean')\n",
    "mu_sex\n",
    "(tips.total_bill - mu_sex).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Why is this useful?*\n",
    "\n",
    "- Useful for fixed effects computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Joining DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Until now we've worked with one DataFrame at a time.\n",
    "\n",
    "We will now learn to put them together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some DataFrames\n",
    "Let's make some data to play with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value_left\n",
      "0   A           0\n",
      "1   B           1\n",
      "2   C           2\n",
      "3   D           3 \n",
      "   key  value_right\n",
      "0   C            4\n",
      "1   D            5\n",
      "2   E            6\n",
      "3   F            7\n"
     ]
    }
   ],
   "source": [
    "left = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'value_left': range(4)})    \n",
    "right = pd.DataFrame({'key': ['C', 'D', 'E', 'F'], 'value_right': range(4,8)})\n",
    "print(left,'\\n', right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Merging data\n",
    "The forthcoming figures all follow this convention:\n",
    "\n",
    "-  <font color=\"blue\">blue</font>: rows in merge output\n",
    "-  <font color=\"red\">red</font>: rows excluded from output (i.e., removed)\n",
    "-  <font color=\"green\">green</font>: missing values replaced with NaNs \n",
    "\n",
    "We use `merge` which is pandas function and a method for dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inner merge (default)\n",
    "This merge only uses only *shared* keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value_left  value_right\n",
      "0   C           2            4\n",
      "1   D           3            5\n"
     ]
    }
   ],
   "source": [
    "print(pd.merge(left, right, on='key', how='inner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center><img src='https://i.stack.imgur.com/YvuOa.png' alt=\"Drawing\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Left merge\n",
    "This merge uses only *left* keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value_left  value_right\n",
      "0   A           0          NaN\n",
      "1   B           1          NaN\n",
      "2   C           2          4.0\n",
      "3   D           3          5.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.merge(left, right, on='key', how='left'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center><img src='https://i.stack.imgur.com/BECid.png' alt=\"Drawing\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Right merge\n",
    "This merge uses only *right* keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value_left  value_right\n",
      "0   C         2.0            4\n",
      "1   D         3.0            5\n",
      "2   E         NaN            6\n",
      "3   F         NaN            7\n"
     ]
    }
   ],
   "source": [
    "print(pd.merge(left, right, on='key', how='right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center><img src='https://i.stack.imgur.com/8w1US.png' alt=\"Drawing\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outer merge\n",
    "This merge uses *all* keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value_left  value_right\n",
      "0   A         0.0          NaN\n",
      "1   B         1.0          NaN\n",
      "2   C         2.0          4.0\n",
      "3   D         3.0          5.0\n",
      "4   E         NaN          6.0\n",
      "5   F         NaN          7.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.merge(left, right, on='key', how='outer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center><img src='https://i.stack.imgur.com/euLoe.png' alt=\"Drawing\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview of merge types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center><img src='https://www.dofactory.com/Images/sql-joins.png' alt=\"Drawing\" style=\"width: 600px;\"/></center>\n",
    "\n",
    "More merge type exists, see [this post](https://stackoverflow.com/questions/53645882/pandas-merging-101) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Joining DataFrames\n",
    "\n",
    "We can also join by keys in the index. This is possible with `join` or `concat`:\n",
    "- both methods work vertically and horizontally.\n",
    "- `concat` works with  multiple DataFrames at once;\n",
    "\n",
    "Requirement: overlapping index keys or column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = left.set_index('key')\n",
    "df1 = right.set_index('key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Horizontal join \n",
    "\n",
    "Works like `merge` where keys is now the index! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     value_left  value_right\n",
      "key                         \n",
      "C             2            4\n",
      "D             3            5\n"
     ]
    }
   ],
   "source": [
    "print(df0.join(df1, how='inner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vertical join \n",
    "\n",
    "`concat` on axis=0 stacks the dataframes on top of each other!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     value_left  value_right\n",
      "key                         \n",
      "A           0.0          NaN\n",
      "B           1.0          NaN\n",
      "C           2.0          NaN\n",
      "D           3.0          NaN\n",
      "C           NaN          4.0\n",
      "D           NaN          5.0\n",
      "E           NaN          6.0\n",
      "F           NaN          7.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df0, df1], join='outer', axis=0, sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vertical and horizontal\n",
    "\n",
    "An overview of `concat`/`join` operations (left: horizontal, right: vertical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center><img src='https://i.stack.imgur.com/1rb1R.jpg' alt=\"Drawing\" style=\"width: 750px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Putting it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from pandas_datareader import data\n",
    "stocks = ['aapl', 'goog', 'msft', 'amzn', 'fb']\n",
    "def load_stock(s):\n",
    "    return data.DataReader(s, data_source='yahoo', start='2000')['Adj Close']\n",
    "load_stock('aapl').head()\n",
    "stock_dfs = {s:load_stock(s) for s in stocks} # dictionary of all stock price\n",
    "stock_df = pd.concat(stock_dfs, axis=1) # horizontal join\n",
    "stock_df.plot(logy=True, figsize=(10,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Methods chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Method chain\n",
    "\n",
    "We iteratively apply methods on dataframes. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby('sex').survived.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Method chain (2)\n",
    "\n",
    "*Suppose we want to filter out teenagers and adults - is this possible?* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic.query(\"age < 13\")[['age','sex','survived']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Method chain (3)\n",
    "\n",
    "*And how do we make new variables?* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(titanic.assign(has_sibsp=lambda df: df.sibsp>0)[['sibsp','has_sibsp']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Method chain (4)\n",
    "\n",
    "*The lines get very long, what do we do?* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "titanic\\\n",
    "    .query(\"age < 13\")\\\n",
    "    .groupby('sex')\\\n",
    "    .survived\\\n",
    "    .mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Beyond pandas\n",
    "\n",
    "If you want more sophisticated data processing tools for big data. \n",
    "\n",
    "Single machine\n",
    "- `multiprocessing` and `joblib` for executing code in parallel (using multiple cores)\n",
    "\n",
    "Multiple machines (cluster)\n",
    "- `dask` uses a pandas like syntax, also useful for parallelizing\n",
    "- `pyspark` is Python based but uses a  (multiple machines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The end\n",
    "[Return to agenda](#Agenda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Code for plots\n",
    "### Load software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "SMALL_SIZE = 16\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
